{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import get_optimal_value, get_performance, precompute_optimal_values, generate_p_grid, compute_portfolio_worst_approx_ratio\n",
    "from taxi_portfolio_main import get_optimum\n",
    "from portfolio import portfolio_with_line_search\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in [0.95]:\n",
    "    uniform_grid = generate_p_grid(N=4, alpha=alpha, grid_size=30)\n",
    "    uniform_portfolio_dict, uniform_portfolio_vectors, uniform_grid = precompute_optimal_values(get_optimum=get_optimum, N=4, alpha=alpha) \n",
    "    np.save(f'portfolios/{alpha}_uniform.npy', uniform_portfolio_dict)\n",
    "    print('\\n\\n')\n",
    "    print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# Compute metric for Jai's policy and Uniform Sample\n",
    "# Compute Jai's policy, and save precomputed values in cache\n",
    "\n",
    "\n",
    "for alpha in [0.5, 0.6, 0.7, 0.8, 0.95]:\n",
    "\n",
    "    print('Starting Jay Algorithm')\n",
    "    # return list of tuples, where first value is p and rest are optimal vector\n",
    "    portfolio = portfolio_with_line_search(alpha, get_optimum, mu=0.5) \n",
    "\n",
    "\n",
    "    portfolio_p_vals = [i[0] for i in portfolio]\n",
    "    portfolio_opt_vecs = [i[1:] for i in portfolio]\n",
    "    portfolio_K = len(portfolio_p_vals)\n",
    "    initial_p = min(portfolio_p_vals)\n",
    "\n",
    "\n",
    "    file_path = f'portfolios/{alpha}_main.npy'\n",
    "    np.save(file_path, portfolio)\n",
    "\n",
    "\n",
    "    print(f'\\n\\nFound {portfolio_K} policies. Minimum p: {initial_p}')\n",
    "    print('#'*100)\n",
    "    print('Time taken: ', time.time()-start)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from taxi_portfolio_main import get_optimum\n",
    "np.random.seed(0)\n",
    "# random_idx = np.random.choice(np.arange(uniform_grid_size),\n",
    "#                                     size=5, replace=False)\n",
    "\n",
    "for alpha in [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:\n",
    "\n",
    "    portfolio_main = np.load(f'portfolios/{alpha}_main.npy', allow_pickle=True)\n",
    "    portfolio_main = list(portfolio_main.flatten()[0])\n",
    "    portfolio_main = np.array([list(i) for i in portfolio_main])\n",
    "    # initial_p = portfolio_main.min(axis=1)[0]\n",
    "    initial_p = portfolio_main[:, 0].min()\n",
    "    portfolio_K = len(portfolio_main)\n",
    "    print(alpha, initial_p)\n",
    "    # dict from p to p_mean at optimal policy for uniformly sampled p\n",
    "    step = (1- initial_p) / (portfolio_K) ###TODO: do non uniform sampling\n",
    "    print(f'Step size: {step}')\n",
    "    random_p = np.arange(initial_p, 1, step)\n",
    "    print(random_p)\n",
    "\n",
    "    random_opt_vecs = []\n",
    "    random_portfolio = []\n",
    "    for p in random_p:\n",
    "        p_mean, vectors = get_optimum(p)\n",
    "        random_opt_vecs.append(vectors)\n",
    "        random_portfolio.append([p]+list(vectors))\n",
    "    \n",
    "    np.save(f'portfolios/{alpha}_random.npy', random_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxi_portfolio_main import get_optimum\n",
    "from evaluation import get_performance\n",
    "from heuristic import budget_portfolio_with_suboptimalities\n",
    "\n",
    "\n",
    "def get_optimum_policy(p):\n",
    "    p_mean, vectors = get_optimum(p)\n",
    "    return vectors\n",
    "\n",
    "\n",
    "for alpha in [0.5, 0.6, 0.7, 0.9, 0.95]:\n",
    "    portfolio_main = np.load(f'portfolios/{alpha}_main.npy', allow_pickle=True)\n",
    "    portfolio_main = list(portfolio_main.flatten()[0])\n",
    "    portfolio_main = np.array([list(i) for i in portfolio_main])\n",
    "    initial_p = portfolio_main.min(axis=1)[0]\n",
    "    initial_p = portfolio_main[:, 0].min()\n",
    "    initial_p = -13.15\n",
    "    portfolio_K = len(portfolio_main)\n",
    "    print(alpha, initial_p, portfolio_K)\n",
    "\n",
    "    print(f'\\talpha {alpha}, init p: {initial_p}, K {portfolio_K}')\n",
    "    portfolio_heuristic = budget_portfolio_with_suboptimalities(initial_p, portfolio_K, get_optimum_policy, get_performance)\n",
    "    print(portfolio_heuristic)\n",
    "    np.save(f'portfolios/{alpha}_heuristic.npy', portfolio_heuristic)\n",
    "    print('#'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxi_portfolio_main import get_optimum\n",
    "from evaluation import get_performance\n",
    "from heuristic import budget_portfolio_with_suboptimalities\n",
    "\n",
    "\n",
    "def get_optimum_policy(p):\n",
    "    p_mean, vectors = get_optimum(p)\n",
    "    return vectors\n",
    "\n",
    "\n",
    "# for alpha in [0.6, 0.8]:\n",
    "for alpha in [0.5, 0.6, 0.7, 0.9, 0.95]:\n",
    "    portfolio_main = np.load(f'portfolios/{alpha}_main.npy', allow_pickle=True)\n",
    "    portfolio_main = list(portfolio_main.flatten()[0])\n",
    "    portfolio_main = np.array([list(i) for i in portfolio_main])\n",
    "    initial_p = portfolio_main.min(axis=1)[0]\n",
    "    initial_p = portfolio_main[:, 0].min()\n",
    "    initial_p = -13.15\n",
    "    portfolio_K = len(portfolio_main)\n",
    "    print(alpha, initial_p, portfolio_K)\n",
    "\n",
    "    print(f'\\talpha {alpha}, init p: {initial_p}, K {portfolio_K}')\n",
    "    portfolio_heuristic = budget_portfolio_with_suboptimalities(initial_p, portfolio_K, get_optimum_policy, get_performance)\n",
    "    print(portfolio_heuristic)\n",
    "    np.save(f'portfolios/{alpha}_heuristic.npy', portfolio_heuristic)\n",
    "    print('#'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Results in Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-27.02681467 -26.74371553 -26.46061639 -26.17751725 -25.89441812\n",
      " -25.61131898 -25.32821984 -25.0451207  -24.76202156 -24.47892243\n",
      " -24.19582329 -23.91272415 -23.62962501 -23.34652587 -23.06342674\n",
      " -22.7803276  -22.49722846 -22.21412932 -21.93103018 -21.64793104\n",
      " -21.36483191 -21.08173277 -20.79863363 -20.51553449 -20.23243535\n",
      " -19.94933622 -19.66623708 -19.38313794 -19.1000388  -18.81693966\n",
      " -18.53384053 -18.25074139 -17.96764225 -17.68454311 -17.40144397\n",
      " -17.11834484 -16.8352457  -16.55214656 -16.26904742 -15.98594828\n",
      " -15.70284915 -15.41975001 -15.13665087 -14.85355173 -14.57045259\n",
      " -14.28735346 -14.00425432 -13.72115518 -13.43805604 -13.1549569\n",
      " -12.87185776 -12.58875863 -12.30565949 -12.02256035 -11.73946121\n",
      " -11.45636207 -11.17326294 -10.8901638  -10.60706466 -10.32396552\n",
      " -10.04086638  -9.75776725  -9.47466811  -9.19156897  -8.90846983\n",
      "  -8.62537069  -8.34227156  -8.05917242  -7.77607328  -7.49297414\n",
      "  -7.209875    -6.92677587  -6.64367673  -6.36057759  -6.07747845\n",
      "  -5.79437931  -5.51128018  -5.22818104  -4.9450819   -4.66198276\n",
      "  -4.37888362  -4.09578449  -3.81268535  -3.52958621  -3.24648707\n",
      "  -2.96338793  -2.68028879  -2.39718966  -2.11409052  -1.83099138\n",
      "  -1.54789224  -1.2647931   -0.98169397  -0.69859483  -0.41549569\n",
      "  -0.13239655   0.15070259   0.43380172   0.71690086   1.        ]\n",
      "{-27.0268146679298: 187.09790871280217, -26.743715529869903: 197.255680535353, -26.460616391810003: 171.61557785431597, -26.177517253750107: 164.24232067115986, -25.89441811569021: 160.32787735867498, -25.611318977630315: 157.19554344984826, -25.328219839570416: 147.88040865977402, -25.04512070151052: 213.46606127475994, -24.762021563450624: 206.59097881134534, -24.478922425390728: 162.7954150083254, -24.19582328733083: 201.4197948289298, -23.912724149270932: 165.40409118878733, -23.629625011211036: 200.89793926433333, -23.346525873151137: 170.63343120630333, -23.06342673509124: 185.3368862888378, -22.780327597031345: 178.056985385943, -22.49722845897145: 147.95214225794646, -22.21412932091155: 179.94749008374356, -21.931030182851654: 183.65851454896577, -21.647931044791758: 178.32831395291262, -21.364831906731858: 159.662019109024, -21.081732768671962: 149.6571258522304, -20.798633630612066: 173.21527478009784, -20.51553449255217: 163.29421257653613, -20.23243535449227: 176.23051962459112, -19.949336216432375: 156.85884349128642, -19.66623707837248: 171.77130569881797, -19.38313794031258: 193.21646683011895, -19.100038802252683: 157.81728197983358, -18.816939664192788: 190.19559539730147, -18.53384052613289: 198.8087741867034, -18.250741388072996: 186.610785031298, -17.967642250013096: 165.42779963981002, -17.684543111953197: 196.96589824724782, -17.4014439738933: 177.56836368128344, -17.118344835833405: 189.64486443363396, -16.83524569777351: 183.57503076503167, -16.552146559713613: 190.230299730709, -16.269047421653717: 200.45236317994087, -15.985948283593817: 178.50722523364718, -15.702849145533921: 163.69055496935357, -15.419750007474024: 161.6329220079637, -15.136650869414126: 168.3262144640317, -14.85355173135423: 176.28768151884904, -14.570452593294332: 190.31271722098916, -14.287353455234436: 190.94406768675165, -14.004254317174539: 170.48984311836648, -13.721155179114643: 224.31908553444296, -13.438056041054745: 198.63393651440637, -13.154956902994847: 165.7000859261495, -12.871857764934951: 183.8220550216568, -12.588758626875054: 180.46977343371805, -12.305659488815158: 165.92866540609083, -12.02256035075526: 173.82976237568744, -11.739461212695364: 189.52270223573478, -11.456362074635466: 180.05257697514133, -11.173262936575568: 218.9869551843255, -10.890163798515673: 168.88450744637967, -10.607064660455777: 176.14168239427462, -10.323965522395877: 183.6148269348517, -10.040866384335981: 187.43675324102594, -9.757767246276085: 182.46701979131552, -9.47466810821619: 187.4157192982959, -9.19156897015629: 204.76051582488836, -8.908469832096394: 177.96261682920357, -8.625370694036498: 185.23758925884295, -8.342271555976598: 193.48314237285572, -8.059172417916702: 213.6337660777959, -7.776073279856806: 179.9077388238207, -7.4929741417969105: 205.47687632668024, -7.209875003737011: 177.9796972410053, -6.926775865677115: 212.75394114853947, -6.643676727617219: 216.79579242883, -6.3605775895573196: 213.4516598571051, -6.077478451497424: 221.28110792457983, -5.794379313437528: 240.28402940408256, -5.511280175377632: 239.3814022225323, -5.228181037317732: 222.39348450518722, -4.945081899257836: 234.52001667110812, -4.66198276119794: 226.98222659770585, -4.378883623138044: 251.56770747331072, -4.095784485078145: 251.27745629050187, -3.812685347018249: 229.8186360643021, -3.529586208958353: 238.2763819634125, -3.2464870708984535: 226.93715182636407, -2.9633879328385575: 222.77270789275394, -2.6802887947786616: 229.04924754628559, -2.3971896567187656: 232.72523878034613, -2.114090518658866: 222.9600086205979, -1.8309913805989702: 181.3000526958205, -1.5478922425390742: 183.61372684549997, -1.2647931044791747: 166.00442491691155, -0.9816939664192788: 173.24332305453217, -0.6985948283593828: 165.86046764096446, -0.41549569029948685: 152.87075222750101, -0.13239655223958735: 132.14673027073627, 0.1507025858203086: 130.7485127737174, 0.43380172388020455: 176.16062292172631, 0.716900861940104: 361.86486688825, 1.0: 592.1867903956514}\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.95\n",
    "uniform_grid = generate_p_grid(N=4, alpha=alpha, grid_size=100)\n",
    "uniform_portfolio_dict = np.load(f'portfolios/{alpha}_uniform.npy', allow_pickle=True).item()\n",
    "print(uniform_grid)\n",
    "print(uniform_portfolio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.5\n",
      "\tp: -2.0, vector: [152.48 164.49 703.37 546.43]\n",
      "Alpha:  0.6\n",
      "\tp: -2.71, vector: [216.05 158.61 597.99 481.47]\n",
      "Alpha:  0.7\n",
      "\tp: -3.89, vector: [179.13 262.56 512.44 414.62]\n",
      "\tp: 0.87, vector: [   0.     29.64 2312.74    0.  ]\n",
      "Alpha:  0.8\n",
      "\tp: 0.86, vector: [   0.      0.   2319.69   29.85]\n",
      "\tp: -6.21, vector: [226.93 205.27 403.53 333.92]\n",
      "\tp: 0.72, vector: [  29.73   29.2  2256.36    0.  ]\n",
      "Alpha:  0.9\n",
      "\tp: -6.17, vector: [199.38 181.63 366.11 327.89]\n",
      "\tp: 0.77, vector: [  29.41    0.   2260.88   29.85]\n",
      "\tp: -13.16, vector: [183.96 190.58 211.88 169.7 ]\n",
      "\tp: -4.82, vector: [174.47 205.15 417.38 346.55]\n",
      "\tp: 0.66, vector: [  28.82   28.37 2159.23    0.  ]\n",
      "\tp: 0.7, vector: [  29.67    0.   2290.17    0.  ]\n",
      "\tp: 0.89, vector: [   0.      0.   2369.95    0.  ]\n",
      "\tp: -10.06, vector: [181.69 177.05 262.23 238.66]\n",
      "Alpha:  0.95\n",
      "\tp: -27.03, vector: [184.22 181.01 218.08 216.92]\n",
      "\tp: 0.66, vector: [  29.64   28.91 2222.91    0.  ]\n",
      "\tp: -6.25, vector: [247.27 202.05 410.43 358.68]\n",
      "\tp: 0.95, vector: [   0.      0.   2369.95    0.  ]\n",
      "\tp: 0.71, vector: [   0.     29.32 2276.46   29.82]\n",
      "\tp: -13.02, vector: [201.37 192.46 247.61 208.16]\n",
      "\tp: 0.81, vector: [   0.      0.   2317.37   29.82]\n",
      "\tp: 0.86, vector: [   0.      0.   2305.81   29.79]\n",
      "\tp: 0.89, vector: [   0.      0.   2319.69   29.85]\n",
      "\tp: 0.78, vector: [   0.      0.   2310.43   29.82]\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:\n",
    "# for alpha in [0.95]:\n",
    "    portfolio_main = np.load(f'portfolios/{alpha}_main.npy', allow_pickle=True)\n",
    "    portfolio_main = list(portfolio_main.flatten()[0])\n",
    "    portfolio_main = np.array([list(i) for i in portfolio_main])\n",
    "    portfolio_opt_vecs = [i[1:] for i in portfolio_main]\n",
    "    p = [i[0] for i in portfolio_main]\n",
    "    print('Alpha: ', alpha)\n",
    "    for k in range(len(portfolio_opt_vecs)):\n",
    "        print(f'\\tp: {np.array([p[k]]).round(2)[0]}, vector: {np.array(portfolio_opt_vecs[k]).round(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Main 0.5 0.6614377052119694\n",
      "##########\n",
      "##########\n",
      "Main 0.6 0.6138813373298317\n",
      "##########\n",
      "##########\n",
      "Main 0.7 0.8830897594689889\n",
      "##########\n",
      "##########\n",
      "Main 0.8 0.9773038590280732\n",
      "##########\n",
      "##########\n",
      "Main 0.9 0.8679241869192256\n",
      "##########\n",
      "##########\n",
      "Main 0.95 0.9920462269111545\n",
      "##########\n",
      "##########\n",
      "Heuristic 0.5 0.3721196484062976\n",
      "##########\n",
      "##########\n",
      "Heuristic 0.6 0.3721196484062976\n",
      "##########\n",
      "##########\n",
      "Heuristic 0.7 0.8485821283825611\n",
      "##########\n",
      "##########\n",
      "Heuristic 0.8 0.9273454119061106\n",
      "##########\n",
      "##########\n",
      "Heuristic 0.9 0.9273454119061106\n",
      "##########\n",
      "##########\n",
      "Heuristic 0.95 0.9273454119061106\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for alpha in [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:\n",
    "    random_main = np.load(f'portfolios/{alpha}_random.npy', allow_pickle=True)\n",
    "    random_opt_vecs = [i[1:] for i in random_main]\n",
    "    out = compute_portfolio_worst_approx_ratio(\n",
    "        portfolio_policies = random_opt_vecs,  # list of policies (or policy vectors)\n",
    "        p_to_optval = uniform_portfolio_dict,         # dict p -> optimal performance\n",
    "        p_grid = uniform_grid,              # sorted list of p-values\n",
    "        get_performance=get_performance\n",
    "    )\n",
    "    print('#'*10)\n",
    "    print('Random', alpha, out[0])\n",
    "    print('#'*10)\n",
    "\n",
    "for alpha in [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:\n",
    "# for alpha in [0.95]:\n",
    "    portfolio_main = np.load(f'portfolios/{alpha}_main.npy', allow_pickle=True)\n",
    "    portfolio_main = list(portfolio_main.flatten()[0])\n",
    "    portfolio_main = np.array([list(i) for i in portfolio_main])\n",
    "    portfolio_opt_vecs = [i[1:] for i in portfolio_main]\n",
    "    out = compute_portfolio_worst_approx_ratio(\n",
    "        portfolio_policies = portfolio_opt_vecs,  # list of policies (or policy vectors)\n",
    "        p_to_optval = uniform_portfolio_dict,         # dict p -> optimal performance\n",
    "        p_grid = uniform_grid,              # sorted list of p-values\n",
    "        get_performance=get_performance\n",
    "    )\n",
    "    print('#'*10)\n",
    "    print('Main', alpha, out[0])\n",
    "    print('#'*10)\n",
    "\n",
    "for alpha in [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:\n",
    "# for alpha in [0.8]:\n",
    "    heuristic_main = np.load(f'portfolios/{alpha}_heuristic.npy', allow_pickle=True)\n",
    "    heuristic_opt_vecs = [i[1] for i in heuristic_main]\n",
    "    out = compute_portfolio_worst_approx_ratio(\n",
    "        portfolio_policies = heuristic_opt_vecs,  # list of policies (or policy vectors)\n",
    "        p_to_optval = uniform_portfolio_dict,         # dict p -> optimal performance\n",
    "        p_grid = uniform_grid,              # sorted list of p-values\n",
    "        get_performance=get_performance\n",
    "    )\n",
    "    print('#'*10)\n",
    "    print('Heuristic', alpha, out[0])\n",
    "    print('#'*10)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "welfareMO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
