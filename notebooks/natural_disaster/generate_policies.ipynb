{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b227afdfb2907837",
   "metadata": {},
   "source": [
    "# Generate Policies for Natural Disaster Simulation\n",
    "\n",
    "This notebook generates policies for the natural disaster relief experiment from the paper. For each of the 10000 policies, we record the rewards for each of the 12 clusters used in hte experiment. The policies are stored in 'data/natural_disaster/policy_rewards.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bab4239bd8faeea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T18:30:18.685829Z",
     "start_time": "2025-06-15T18:30:18.302905Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "from pathlib import Path\n",
    "project_root = os.path.join(Path.cwd(), '..', '..')\n",
    "sys.path.insert(0, str(project_root))\n",
    "import numpy as np\n",
    "\n",
    "from src.environments.natural_disaster import (\n",
    "    need_based_policy,\n",
    "    per_capita_need_policy,\n",
    "    population_based_policy,\n",
    "    income_based_policy,\n",
    "    proximity_based_policy,\n",
    "    randomized_weighted_hybrid_policy,\n",
    "    mixed_random_policy_k_increments,\n",
    "    generate_action_space,\n",
    "    simulate_policy_dynamic_with_tpm\n",
    ")\n",
    "import csv\n",
    "import itertools as it\n",
    "import multiprocessing as mp\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "407b168e-8fb8-4ec8-bf8f-547626cac5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Global bonus config (clusters are 1-based ids) ---\n",
    "def make_global_bonus(favored_clusters, per_unit_bonus, unit='k-increments'):\n",
    "    \"\"\"\n",
    "    favored_clusters : iterable of 1-based cluster IDs to favor (e.g., {2, 5})\n",
    "    per_unit_bonus   : float, bonus added to reward per unit allocated\n",
    "    unit             : 'k-increments' -> units = allocation/k\n",
    "                       'absolute'     -> units = allocation\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"clusters\": set(favored_clusters),\n",
    "        \"per_unit_bonus\": float(per_unit_bonus),\n",
    "        \"unit\": unit\n",
    "    }\n",
    "\n",
    "def _run_bonus(args):\n",
    "    \"\"\"\n",
    "    Run all simulations for one (preferred_clusters, per_unit_bonus) config\n",
    "    and write a single CSV. Returns (outfile, n_rows).\n",
    "    \"\"\"\n",
    "    pref, inc, clusters, k, K, horizon, p, epsilon, num_simulations, out_dir = args\n",
    "\n",
    "    # initial state from the ORIGINAL clusters\n",
    "    initial_state = tuple(c['initial_need'] for c in clusters)\n",
    "\n",
    "    # adjust cluster 'initial_need' used for reward normalization (your original new_clusters logic)\n",
    "    new_clusters = []\n",
    "    for c in clusters:\n",
    "        d = c.copy()\n",
    "        d['initial_need'] = c['initial_need'] + k * horizon\n",
    "        new_clusters.append(d)\n",
    "\n",
    "    # action space per worker (cheap to recompute; avoids pickling a big list)\n",
    "    num_clusters = len(clusters)\n",
    "    action_space = generate_action_space(num_clusters, k, K)\n",
    "\n",
    "    # global bonus & output suffix\n",
    "    if pref:\n",
    "        global_bonus = make_global_bonus(favored_clusters=pref, per_unit_bonus=inc, unit='k-increments')\n",
    "        favored = \"-\".join(map(str, sorted(pref)))\n",
    "        suffix = f\"_bonus_{favored}_{inc}\"\n",
    "    else:\n",
    "        global_bonus = None\n",
    "        suffix = \"\"\n",
    "\n",
    "    # deterministic base seed per config (reproducible regardless of process order)\n",
    "    base_seed = (hash((tuple(sorted(pref)) if pref else (), float(inc))) & 0xFFFFFFFF)\n",
    "\n",
    "    # run simulations\n",
    "    rewards_rows = []\n",
    "    for i in range(num_simulations):\n",
    "        seed = base_seed + i\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        rewards, _policy = simulate_policy_dynamic_with_tpm(\n",
    "            initial_state=initial_state,\n",
    "            clusters=new_clusters,\n",
    "            k=k, K=K, p=p, horizon=horizon,\n",
    "            action_space=action_space,\n",
    "            policy_functions={  # use your menu\n",
    "                \"need_based\": need_based_policy,\n",
    "                \"per_capita\": per_capita_need_policy,\n",
    "                \"population_based\": population_based_policy,\n",
    "                \"income_based\": income_based_policy,\n",
    "                \"proximity_based\": proximity_based_policy,\n",
    "                \"weighted_hybrid\": randomized_weighted_hybrid_policy,\n",
    "                \"mixed_random\": mixed_random_policy_k_increments,\n",
    "            },\n",
    "            epsilon=epsilon,\n",
    "            global_bonus=global_bonus\n",
    "        )\n",
    "        rewards_rows.append(rewards)\n",
    "\n",
    "    # write CSV atomically\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    outfile = os.path.join(out_dir, f\"policy_rewards{suffix}.csv\")\n",
    "    tmpfile = outfile + \".tmp\"\n",
    "\n",
    "    with open(tmpfile, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([f\"Cluster_{i+1}_Reward\" for i in range(num_clusters)])\n",
    "        w.writerows(rewards_rows)\n",
    "\n",
    "    os.replace(tmpfile, outfile)\n",
    "    return outfile, len(rewards_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:21:40.438315Z",
     "start_time": "2025-06-15T23:15:11.002864Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating actions\n",
      "Launching 10 bonus configs with 10 workers (fork)…\n",
      "✔ wrote 1000 rows -> ../../data/natural_disaster/policy_rewards.csv\n",
      "✔ wrote 1000 rows -> ../../data/natural_disaster/policy_rewards_bonus_1_0.05.csv\n",
      "✔ wrote 1000 rows -> ../../data/natural_disaster/policy_rewards_bonus_1_0.2.csv\n",
      "✔ wrote 1000 rows -> ../../data/natural_disaster/policy_rewards_bonus_5_0.2.csv\n",
      "✔ wrote 1000 rows -> ../../data/natural_disaster/policy_rewards_bonus_2_0.2.csv\n",
      "✔ wrote 1000 rows -> ../../data/natural_disaster/policy_rewards_bonus_5_0.1.csv\n",
      "✔ wrote 1000 rows -> ../../data/natural_disaster/policy_rewards_bonus_1_0.1.csv\n",
      "✔ wrote 1000 rows -> ../../data/natural_disaster/policy_rewards_bonus_2_0.1.csv\n",
      "✔ wrote 1000 rows -> ../../data/natural_disaster/policy_rewards_bonus_5_0.05.csv\n",
      "✔ wrote 1000 rows -> ../../data/natural_disaster/policy_rewards_bonus_2_0.05.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Use fork so workers inherit the main process state (Linux HPC friendly)\n",
    "    try:\n",
    "        mp.set_start_method('fork', force=True)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "    ## Experimental setup for fixed population size and need\n",
    "    clusters = [\n",
    "        {\"id\": 1, \"density\": \"High\", \"proximity\": \"Far\", \"income\": \"High-Income\", \"population\": 148, \"initial_need\": 100},\n",
    "        {\"id\": 2, \"density\": \"High\", \"proximity\": \"Far\", \"income\": \"Low-Income\", \"population\": 307, \"initial_need\": 300},\n",
    "        {\"id\": 3, \"density\": \"High\", \"proximity\": \"Far\", \"income\": \"Middle-Income\", \"population\": 616, \"initial_need\": 200},\n",
    "        {\"id\": 4, \"density\": \"High\", \"proximity\": \"Near\", \"income\": \"High-Income\", \"population\": 816, \"initial_need\": 50},\n",
    "        {\"id\": 5, \"density\": \"High\", \"proximity\": \"Near\", \"income\": \"Low-Income\", \"population\": 1405, \"initial_need\": 200},\n",
    "        {\"id\": 6, \"density\": \"High\", \"proximity\": \"Near\", \"income\": \"Middle-Income\", \"population\": 2782,\n",
    "         \"initial_need\": 300},\n",
    "        {\"id\": 7, \"density\": \"Low\", \"proximity\": \"Far\", \"income\": \"High-Income\", \"population\": 74, \"initial_need\": 100},\n",
    "        {\"id\": 8, \"density\": \"Low\", \"proximity\": \"Far\", \"income\": \"Low-Income\", \"population\": 203, \"initial_need\": 500},\n",
    "        {\"id\": 9, \"density\": \"Low\", \"proximity\": \"Far\", \"income\": \"Middle-Income\", \"population\": 396, \"initial_need\": 350},\n",
    "        {\"id\": 10, \"density\": \"Low\", \"proximity\": \"Near\", \"income\": \"High-Income\", \"population\": 36, \"initial_need\": 50},\n",
    "        {\"id\": 11, \"density\": \"Low\", \"proximity\": \"Near\", \"income\": \"Low-Income\", \"population\": 113, \"initial_need\": 50},\n",
    "        {\"id\": 12, \"density\": \"Low\", \"proximity\": \"Near\", \"income\": \"Middle-Income\", \"population\": 230, \"initial_need\": 50}\n",
    "    ]\n",
    "\n",
    "\n",
    "    #choose to bias rewards, globally\n",
    "    preferred_clusters = [{1},{2}, {5}]\n",
    "    per_unit_bonuses = [.05, .10, .2]\n",
    "\n",
    "    #true if we also want to baseline with no biasing, otherwise, False\n",
    "    no_bonus = True\n",
    "\n",
    "    # Allocation Parameters\n",
    "    K = 150  # Total additional units to allocate\n",
    "    k = 50  # Allocation increment\n",
    "\n",
    "    # MDP Parameters\n",
    "    horizon = 3  # Number of time steps\n",
    "    initial_state = tuple([cluster['initial_need'] for cluster in clusters])\n",
    "    p = 0.7\n",
    "    num_clusters = len(clusters)\n",
    "\n",
    "    new_clusters = []\n",
    "    for adict in clusters:\n",
    "        adict2 = adict.copy()\n",
    "        adict2['initial_need'] += k * horizon\n",
    "        new_clusters.append(adict2)\n",
    "\n",
    "    policy_functions = {\n",
    "        \"need_based\": need_based_policy,\n",
    "        \"per_capita\": per_capita_need_policy,\n",
    "        \"population_based\": population_based_policy,\n",
    "        \"income_based\": income_based_policy,\n",
    "        \"proximity_based\": proximity_based_policy,\n",
    "        \"weighted_hybrid\": randomized_weighted_hybrid_policy,\n",
    "        \"mixed_random\": mixed_random_policy_k_increments\n",
    "    }\n",
    "\n",
    "    policy_functions_list = [i for i in policy_functions.values()]\n",
    "\n",
    "    # Step 1: Generate Action Space\n",
    "    print('generating actions')\n",
    "    action_space = generate_action_space(num_clusters, k, K)\n",
    "\n",
    "    # Define parameters\n",
    "    epsilon = 0.01  # Include only states with probability > 0.01\n",
    "    ################################################################\n",
    "\n",
    "    # Generate 1000 different policies for the simulation\n",
    "    num_simulations = 1000\n",
    "    simulation_results = []\n",
    "\n",
    "    all_bonuses = list(it.product(preferred_clusters, per_unit_bonuses))\n",
    "    if no_bonus:\n",
    "        all_bonuses.append((set(), 0))  # baseline (no bonus)\n",
    "\n",
    "    out_dir = os.path.join('..', '..', 'data', 'natural_disaster')\n",
    "\n",
    "    # Build tasks (each process handles one CSV end-to-end)\n",
    "    tasks = [\n",
    "        (pref, inc, clusters, k, K, horizon, p, epsilon, 1000, out_dir)\n",
    "        for (pref, inc) in all_bonuses\n",
    "    ]\n",
    "\n",
    "    N_WORKERS = int(os.environ.get(\"N_WORKERS\", mp.cpu_count()))\n",
    "    N_WORKERS = max(1, min(N_WORKERS, len(tasks)))  # don’t spawn more workers than tasks\n",
    "\n",
    "    # Use fork so children inherit the main process state (no pickling of __main__)\n",
    "    try:\n",
    "        mp.set_start_method(\"fork\", force=True)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "    print(f\"Launching {len(tasks)} bonus configs with {N_WORKERS} workers (fork)…\")\n",
    "    with mp.get_context(\"fork\").Pool(processes=N_WORKERS) as pool:\n",
    "        for outfile, n in pool.imap_unordered(_run_bonus, tasks, chunksize=1):\n",
    "            print(f\"✔ wrote {n} rows -> {outfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d0d729-4510-427f-9d2e-e552bc2b0506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
