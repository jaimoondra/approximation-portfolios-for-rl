{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b227afdfb2907837",
   "metadata": {},
   "source": [
    "# Generate Policies for Natural Disaster Simulation\n",
    "\n",
    "This notebook generates policies for the natural disaster relief experiment from the paper. For each of the 10000 policies, we record the rewards for each of the 12 clusters used in hte experiment. The policies are stored in 'data/natural_disaster/policy_rewards.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab4239bd8faeea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T18:30:18.685829Z",
     "start_time": "2025-06-15T18:30:18.302905Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "from pathlib import Path\n",
    "project_root = os.path.join(Path.cwd(), '..', '..')\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.environments.natural_disaster import (\n",
    "    need_based_policy,\n",
    "    per_capita_need_policy,\n",
    "    population_based_policy,\n",
    "    income_based_policy,\n",
    "    proximity_based_policy,\n",
    "    randomized_weighted_hybrid_policy,\n",
    "    mixed_random_policy_k_increments,\n",
    "    generate_action_space,\n",
    "    simulate_policy_dynamic_with_tpm\n",
    ")\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:21:40.438315Z",
     "start_time": "2025-06-15T23:15:11.002864Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating actions\n",
      "Simulation 1 -> Rewards: [0.030108264462809967, 0.03707396694214897, 0.023983864620228217, 0.04095833333333349, 0.03004427390791023, 0.09198044077134944, 0.04316785123966903, 0.5453028183937295, 0.2310494765840213, 0.044355475206611664, 0.04095833333333349, 0.0420833333333335]\n",
      "Simulation 2 -> Rewards: [0.030000000000000034, 0.039706336088154236, 0.02162467532467528, 0.04070833333333348, 0.02207378984651707, 0.07947396694214859, 0.03498870523415947, 0.5516439182030116, 0.0624540771349864, 0.3599519972451773, 0.04416666666666681, 0.037625000000000144]\n",
      "Simulation 3 -> Rewards: [0.03032479338842978, 0.040418319559228776, 0.02152662337662333, 0.037500000000000144, 0.02262987012987008, 0.2597473370064273, 0.04676391184572965, 0.5516363742318289, 0.05910038567493133, 0.060242975206611704, 0.038250000000000145, 0.04579166666666682]\n",
      "Simulation 4 -> Rewards: [0.030119090909090925, 0.03635275482093669, 0.021517709563164057, 0.040958333333333465, 0.03269933097205819, 0.30624471992653696, 0.04892479338842942, 0.5270734371688938, 0.04771998622589541, 0.04144979338842987, 0.04208333333333347, 0.03775000000000013]\n",
      "Simulation 5 -> Rewards: [0.030108264462809935, 0.024295730027548156, 0.021526623376623328, 0.03750000000000013, 0.07602317985045305, 0.6039415059687762, 0.030373636363636384, 0.28822378681924143, 0.016241363636363606, 0.04798977272727286, 0.04208333333333347, 0.04220833333333347]\n",
      "Simulation 6 -> Rewards: [0.034197052341597534, 0.21881703397612554, 0.02142857142857137, 0.04208333333333346, 0.021526623376623318, 0.08039641873278225, 0.03502267217630829, 0.5580805043441428, 0.0359123002754821, 0.09669679752066124, 0.037637500000000115, 0.04430416666666678]\n",
      "Simulation 7 -> Rewards: [0.03407796143250655, 0.027071349862258887, 0.021517709563164063, 0.037625000000000144, 0.2309728453364807, 0.2942237832874183, 0.04293644628099136, 0.39752397753761276, 0.04033370523415975, 0.05775606060606073, 0.04416666666666681, 0.03776250000000014]\n",
      "Simulation 8 -> Rewards: [0.03430531680440743, 0.018125344352617034, 0.021606847697756736, 0.04222083333333347, 0.23978264462809828, 0.37905036730945685, 0.030747272727272745, 0.36526286289468096, 0.016387190082644606, 0.03805795454545468, 0.040708333333333464, 0.03763750000000013]\n",
      "Simulation 9 -> Rewards: [0.030119090909090943, 0.04693746556473845, 0.021428571428571384, 0.037500000000000144, 0.030053187721369487, 0.0767511019283747, 0.040359504132231244, 0.5480566857385064, 0.23884943526170732, 0.052221177685950526, 0.037750000000000145, 0.037750000000000145]\n",
      "Simulation 10 -> Rewards: [0.030108264462809967, 0.029586776859504064, 0.02160684769775675, 0.04070833333333349, 0.07509031877213755, 0.3866970615243322, 0.03044793388429757, 0.464144140707777, 0.02866859504132214, 0.03801859504132247, 0.04095833333333349, 0.03787500000000016]\n",
      "Successfully wrote ../../data/natural_disaster/policy_rewards.csv\n"
     ]
    }
   ],
   "source": [
    "## Experimental setup for fixed population size and need\n",
    "clusters = [\n",
    "    {\"id\": 1, \"density\": \"High\", \"proximity\": \"Far\", \"income\": \"High-Income\", \"population\": 148, \"initial_need\": 100},\n",
    "    {\"id\": 2, \"density\": \"High\", \"proximity\": \"Far\", \"income\": \"Low-Income\", \"population\": 307, \"initial_need\": 300},\n",
    "    {\"id\": 3, \"density\": \"High\", \"proximity\": \"Far\", \"income\": \"Middle-Income\", \"population\": 616, \"initial_need\": 200},\n",
    "    {\"id\": 4, \"density\": \"High\", \"proximity\": \"Near\", \"income\": \"High-Income\", \"population\": 816, \"initial_need\": 50},\n",
    "    {\"id\": 5, \"density\": \"High\", \"proximity\": \"Near\", \"income\": \"Low-Income\", \"population\": 1405, \"initial_need\": 200},\n",
    "    {\"id\": 6, \"density\": \"High\", \"proximity\": \"Near\", \"income\": \"Middle-Income\", \"population\": 2782,\n",
    "     \"initial_need\": 300},\n",
    "    {\"id\": 7, \"density\": \"Low\", \"proximity\": \"Far\", \"income\": \"High-Income\", \"population\": 74, \"initial_need\": 100},\n",
    "    {\"id\": 8, \"density\": \"Low\", \"proximity\": \"Far\", \"income\": \"Low-Income\", \"population\": 203, \"initial_need\": 500},\n",
    "    {\"id\": 9, \"density\": \"Low\", \"proximity\": \"Far\", \"income\": \"Middle-Income\", \"population\": 396, \"initial_need\": 350},\n",
    "    {\"id\": 10, \"density\": \"Low\", \"proximity\": \"Near\", \"income\": \"High-Income\", \"population\": 36, \"initial_need\": 50},\n",
    "    {\"id\": 11, \"density\": \"Low\", \"proximity\": \"Near\", \"income\": \"Low-Income\", \"population\": 113, \"initial_need\": 50},\n",
    "    {\"id\": 12, \"density\": \"Low\", \"proximity\": \"Near\", \"income\": \"Middle-Income\", \"population\": 230, \"initial_need\": 50}\n",
    "]\n",
    "\n",
    "\n",
    "#choose to bias rewards, globally\n",
    "# global_bonus = {\n",
    "#     \"clusters\": [2],              # 1-based IDs to boost (optional)\n",
    "#     \"category\": \"Low-Income\",     # or boost a category (optional)\n",
    "#     \"weight\": 0.2,                # 20% boost\n",
    "#     \"max_boost\": 1.0              # optional safety cap on total boost factor\n",
    "# }\n",
    "\n",
    "global_bonus=None\n",
    "\n",
    "\n",
    "# Allocation Parameters\n",
    "K = 150  # Total additional units to allocate\n",
    "k = 50  # Allocation increment\n",
    "\n",
    "# MDP Parameters\n",
    "horizon = 3  # Number of time steps\n",
    "initial_state = tuple([cluster['initial_need'] for cluster in clusters])\n",
    "p = 0.7\n",
    "num_clusters = len(clusters)\n",
    "\n",
    "new_clusters = []\n",
    "for adict in clusters:\n",
    "    adict2 = adict.copy()\n",
    "    adict2['initial_need'] += k * horizon\n",
    "    new_clusters.append(adict2)\n",
    "\n",
    "policy_functions = {\n",
    "    \"need_based\": need_based_policy,\n",
    "    \"per_capita\": per_capita_need_policy,\n",
    "    \"population_based\": population_based_policy,\n",
    "    \"income_based\": income_based_policy,\n",
    "    \"proximity_based\": proximity_based_policy,\n",
    "    \"weighted_hybrid\": randomized_weighted_hybrid_policy,\n",
    "    \"mixed_random\": mixed_random_policy_k_increments\n",
    "}\n",
    "\n",
    "policy_functions_list = [i for i in policy_functions.values()]\n",
    "\n",
    "# Step 1: Generate Action Space\n",
    "print('generating actions')\n",
    "action_space = generate_action_space(num_clusters, k, K)\n",
    "\n",
    "# Define parameters\n",
    "epsilon = 0.01  # Include only states with probability > 0.01\n",
    "################################################################\n",
    "# Generate 1000 different policies for the simulation\n",
    "num_simulations = 1000\n",
    "simulation_results = []\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    rewards, policy = simulate_policy_dynamic_with_tpm(\n",
    "        initial_state=initial_state,\n",
    "        clusters=new_clusters,\n",
    "        k=k,\n",
    "        K=K,\n",
    "        p=p,\n",
    "        horizon=horizon,\n",
    "        action_space=action_space,\n",
    "        policy_functions=policy_functions,\n",
    "        epsilon=0.01,\n",
    "        global_bonus=global_bonus\n",
    "    )\n",
    "    simulation_results.append({\"simulation\": i + 1, \"rewards\": rewards, \"policy\": policy})\n",
    "\n",
    "# Print rewards for the first few simulations\n",
    "for result in simulation_results[:10]:\n",
    "    print(f\"Simulation {result['simulation']} -> Rewards: {result['rewards']}\")\n",
    "    \n",
    "if global_bonus:\n",
    "    bonus = '_bonus'\n",
    "else:\n",
    "    bonus=''\n",
    "\n",
    "output_csv = os.path.join('..', '..', 'data', 'natural_disaster', f'policy_rewards{bonus}.csv')\n",
    "\n",
    "# Open the file for writing\n",
    "with open(output_csv, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writerow([f\"Cluster_{i + 1}_Reward\" for i in range(num_clusters)])\n",
    "\n",
    "    # Write only the reward vectors\n",
    "    for result in simulation_results:\n",
    "        writer.writerow(result[\"rewards\"])\n",
    "    print(f'Successfully wrote {output_csv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0860589b207a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
