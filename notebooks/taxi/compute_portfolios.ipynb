{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from src.portfolio import compute_portfolio_worst_approx_ratio, Portfolio, Policy\n",
    "from src.p_mean import generate_p_grid, generalized_p_mean\n",
    "from src.environments.taxi.main import get_optimum\n",
    "from src.portfolio import portfolio_with_line_search, portfolio_of_random_norms, portfolio_of_random_policies, budget_portfolio_with_suboptimalities\n",
    "import time\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def precompute_optimal_values(get_optimum, N, alpha, grid_size=100):\n",
    "    \"\"\"\n",
    "    Precompute the optimal performance (max over all policies) for p\n",
    "    on a grid from p_min = -log2(N) to p_max = 1, in increments of 'step'.\n",
    "\n",
    "    :return:\n",
    "       p_to_optval: dict mapping p -> float (optimal performance at that p)\n",
    "       p_grid:      sorted list of p-values used\n",
    "    \"\"\"\n",
    "    p_vals = generate_p_grid(N=N, alpha=alpha, grid_size=grid_size)\n",
    "    print('grid: ', p_vals)\n",
    "    p_to_optval = {}\n",
    "    p_to_optvec = {}\n",
    "    for p_val in p_vals:\n",
    "        print('p val: ', p_val)\n",
    "        p_mean, vectors = get_optimum(p_val)\n",
    "        p_to_optval[p_val] = p_mean\n",
    "        p_to_optvec[p_val] = vectors\n",
    "\n",
    "    p_vals = sorted(p_vals)\n",
    "    return p_to_optval, p_to_optvec, p_vals\n",
    "\n",
    "\n",
    "def get_optimum_policy(p):\n",
    "    \"\"\"\n",
    "    Get the optimal policy for a given p value.\n",
    "    \"\"\"\n",
    "    p_mean, vectors = get_optimum(p)\n",
    "    return vectors\n"
   ],
   "id": "eec79e6faee2054c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate the p grid and precompute the optimal values",
   "id": "97901c908abedf63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "uniform_portfolio_dict, uniform_portfolio_vectors, uniform_grid = precompute_optimal_values(get_optimum=get_optimum, N=4, alpha=0.95)\n",
    "np.save(f'portfolios/{0.95}_uniform.npy', uniform_portfolio_dict)\n",
    "print('\\n\\n')\n",
    "print('#'*100)"
   ],
   "id": "78ee94d827b0fdc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# p-Mean Portfolio with Line Search",
   "id": "eeac553bb250b089"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_optimal_value(p):\n",
    "    p_mean, vectors = get_optimum(p)\n",
    "    return p_mean\n",
    "\n",
    "for alpha in [0.5, 0.6, 0.7, 0.8, 0.95]:\n",
    "    portfolio = portfolio_with_line_search(\n",
    "        alpha=alpha, get_performance=generalized_p_mean, get_optimum_policy=get_optimum_policy,\n",
    "        d=4,\n",
    "    )\n",
    "    oracle_calls = portfolio.oracle_calls\n",
    "    \n",
    "    policies = portfolio.policies\n",
    "    portfolio_p_vals = [policy.p for policy in policies]\n",
    "    portfolio_K = len(portfolio_p_vals)\n",
    "    initial_p = min(portfolio_p_vals)\n",
    "\n",
    "    file_path = f'portfolios/{alpha}_main.npy'\n",
    "    np.save(file_path, [(policy.p, policy) for policy in policies])\n",
    "    \n",
    "    print(f'alpha: {alpha}')\n",
    "    print(f'\\n\\nFound {portfolio_K} policies. Minimum p: {initial_p}')\n",
    "    print(f'Oracle calls: {oracle_calls}')\n",
    "    \n",
    "    approx = compute_portfolio_worst_approx_ratio(\n",
    "        portfolio=portfolio,\n",
    "        get_optimal_value=get_optimal_value,\n",
    "        p_grid=uniform_grid,\n",
    "        get_performance=generalized_p_mean\n",
    "    )\n",
    "    print('Worst Approximation Ratio: ', approx)\n"
   ],
   "id": "6ee96d286b905b25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Norm Portfolio",
   "id": "6d8f28799bd2d83a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "N = 4\n",
    "alpha_0 = 0.90\n",
    "initial_p = - np.log(N)/np.log(1/alpha_0)\n",
    "\n",
    "\n",
    "for portfolio_K in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    print(f'Portfolio K: {portfolio_K}')\n",
    "    \n",
    "    random_norm_portfolio = portfolio_of_random_norms(\n",
    "        initial_p=initial_p,\n",
    "        K=portfolio_K,\n",
    "        get_optimum_policy=get_optimum_policy,\n",
    "    )\n",
    "\n",
    "    approx = compute_portfolio_worst_approx_ratio(\n",
    "        portfolio=random_norm_portfolio,\n",
    "        get_optimal_value=get_optimal_value,\n",
    "        p_grid=uniform_grid,\n",
    "        get_performance=generalized_p_mean\n",
    "    )\n",
    "    print('Worst Approximation Ratio: ', approx)\n",
    "\n",
    "    np.save(f'portfolios/{portfolio_K}_random_norm.npy', random_norm_portfolio)"
   ],
   "id": "59f6e2034a60ed7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Heuristic/binary search portfolio",
   "id": "8c141aa92738fe4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_optimum_policy(p):\n",
    "    p_mean, vectors = get_optimum(p)\n",
    "    return vectors\n",
    "\n",
    "\n",
    "def get_optimal_value(p):\n",
    "    p_mean, vectors = get_optimum(p)\n",
    "    return p_mean\n",
    "\n",
    "\n",
    "for portfolio_K in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    initial_p = -25  # Starting point for the heuristic portfolio\n",
    "    print(f'Portfolio K: {portfolio_K}')\n",
    "    portfolio_heuristic = budget_portfolio_with_suboptimalities(\n",
    "        initial_p=initial_p, \n",
    "        K=portfolio_K,\n",
    "        get_optimum_policy=get_optimum_policy,\n",
    "        get_performance=generalized_p_mean\n",
    "    )\n",
    "\n",
    "    approx = compute_portfolio_worst_approx_ratio(\n",
    "        portfolio=portfolio_heuristic,\n",
    "        get_optimal_value=get_optimal_value,\n",
    "        p_grid=uniform_grid,\n",
    "        get_performance=generalized_p_mean\n",
    "    )\n",
    "    print('Worst Approximation Ratio: ', approx)\n",
    "    \n",
    "    np.save(f'portfolios/{portfolio_K}_heuristic.npy', portfolio_heuristic)\n",
    "    print('#'*10)"
   ],
   "id": "392d20db3b270099",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random policy portfolio",
   "id": "751cbff8754f1acb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_random_policy():\n",
    "    \"\"\"\n",
    "    Generate a random policy for a given p value.\n",
    "    \"\"\"\n",
    "    p = np.random.uniform(-100, 1)\n",
    "    p_mean, vectors = get_optimum(p, episodes=150)\n",
    "    return Policy(vectors)\n",
    "\n",
    "\n",
    "for portfolio_K in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    print(f'Portfolio K: {portfolio_K}')\n",
    "    portfolio = Portfolio()\n",
    "    for _ in range(portfolio_K):\n",
    "        policy = get_random_policy()\n",
    "        portfolio.add_policy(policy)\n",
    "\n",
    "    approx = compute_portfolio_worst_approx_ratio(\n",
    "        portfolio=portfolio,\n",
    "        get_optimal_value=get_optimal_value,\n",
    "        p_grid=uniform_grid,\n",
    "        get_performance=generalized_p_mean\n",
    "    )\n",
    "    print('Worst Approximation Ratio: ', approx)\n",
    "\n",
    "    np.save(f'portfolios/{portfolio_K}_random_policy.npy', portfolio_heuristic)\n",
    "    print('#'*10)"
   ],
   "id": "ce070be83d9afaeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c013952d1994dd99",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
